---
title: "Geotag Sense of Place"
author: "Jamie Afflerbach"
date: "12/19/2019"
output: html_document
---

```{r setup, include=FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE)

library(leaflet)
library(sf)
library(kableExtra)
library(mapview)
library(RColorBrewer)
library(raster)
library(tidyverse)
library(ggmap)
library(cowplot)
library(viridis)
```

# Getting a "sense" of the data

This data is filtered to only geo-tagged tweets in our bounding box. Also limited the the english language

```{r load_data, echo = F}
data       <- read_csv("data/geotag_sb_tweets.csv") %>%
  separate(created_at, into = c("Day", "Year"), sep = 26) %>%
  mutate(Year = as.numeric(Year)) %>%
  separate(Day, into = c("Day", "Date"), sep = 4) %>%
  separate(Date, into = c("Date", "Time"), sep = 7) %>%
  separate(Time, into = c("Time", "Extra"), sep = 9) %>%
  select(-Extra, -tweet_id, -language, -geo_type, -id, -geo_coordinates, -location, -user_id, -Day) %>%
  separate(Date, into = c("Month", "Day"), sep = " ") %>%
  mutate(Day = as.numeric(Day)) %>%
  mutate(month_num = match(Month,month.abb)) %>%
  mutate(date = as.Date(paste0(month_num, "/", Day, "/",Year),tryFormats = "%m/%d/%Y"))
```

We have a total of `r nrow(data)` geotagged tweets.

What is in the data? tweet text, retweets, favorites, location

```{r, echo = F}
kable(sample_n(data, 20)) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), font_size = 10, fixed_thead = T)
```

There are tweets from people without a designated location. For these, we assume they are tourists. But that is likley not true for all of them. One method to determine locals vs tourists would be to look at previous tweets and if a certain percent in a given time frame are within Santa Barbara, we can assume they are locals. There is a paper on this.

------

Map of all tweets

```{r, eval = F, echo = F}
#map
map <- leaflet(data) %>%
  # Base groups
  addProviderTiles(providers$CartoDB.Positron) %>%
  # Overlay groups
  addCircleMarkers(lng = ~lon, lat = ~lat, popup = ~full_text,
                   radius = 3, stroke = FALSE, fillOpacity = 1, group = "All tweets") %>%
    addCircleMarkers(data = data %>% filter(user_type == "tourist"), lng = ~lon, lat = ~lat, popup = ~full_text,
                   radius = 3, stroke = FALSE,
                   color = "gray", fillOpacity = 0.5, group = "Tourists") %>%
  addCircleMarkers(data = data %>% filter(user_type == "local"), lng = ~lon, lat = ~lat, popup = ~full_text,
                   radius = 3, stroke = FALSE,
                   color = "navy", fillOpacity = 0.8, group = "Locals") %>%
  # Layers control
  addLayersControl(
    overlayGroups = c("All tweets", "Tourists", "Locals"),
    options = layersControlOptions(collapsed = FALSE)
  ) %>%
 hideGroup("Tourists") %>%
 hideGroup("Locals")

map
```

```{r, echo = F}
cols      = c(brewer.pal(9,"OrRd")[3:9])

#santa barbara
sb.map <- get_map("santa barbara, california", zoom = 14, maptype = "toner-lite") 

ggmap(sb.map,  legend="none") +
  coord_equal() +
    labs(x = NULL, y = NULL) +
    theme(axis.text = element_blank()) +
    geom_hex(data = data, aes(x=lon, y=lat, fill = cut(..count.., c(0, 10, 50, 100,
                                    500, 1000, 5000, Inf))), bins=100) +
       scale_fill_manual(
        values = cols,
        labels = c("<10 ", "10-49 ", "50-99 ",
                   "100-499 ", "500-999 ", "1000-4999 ", "5000+")
    ) +
  labs(fill = "# Tweets",
       title = "Tweets in Santa Barbara 2015-2019")

```



```{r, echo = F}
cols      = c(brewer.pal(9,"OrRd")[3:9])

#santa barbara
sb.map <- get_map("santa barbara, california", zoom = 11, maptype = "toner-lite") 

ggmap(sb.map,  legend="none") +
  coord_equal() +
    labs(x = NULL, y = NULL) +
    theme(axis.text = element_blank()) +
    geom_hex(data = data, aes(x=lon, y=lat, fill = cut(..count.., c(0, 10, 50, 100,
                                    500, 1000, 5000, Inf))), bins=100) +
       scale_fill_manual(
        values = cols,
        labels = c("<10 ", "10-49 ", "50-99 ",
                   "100-499 ", "500-999 ", "1000-4999 ", "5000+")
    ) +
  labs(fill = "# Tweets",
       title = "Tweets in larger SB area 2015-2019")

```

## Timeline of all tweets

```{r, echo = F}
time_df <- data %>%
  group_by(date) %>%
  summarize(num_tweets = n())

time_df_user_type <- data %>%
  group_by(date, user_type) %>%
  summarize(num_tweets = n())

#create rectangles for shading significant events

rects <- data.frame(start = as.Date(c("2015-05-19", "2016-11-08", "2017-12-04", "2018-01-08")),
                    end   = as.Date(c("2015-05-22", "2016-11-10", "2017-12-06", "2018-01-11")),
                    group = c(1, 2, 3, 4))

text_df <- data.frame(x = as.Date("2015-05-19"),
                      y = 64,
                      label = "Refugio oil spill 05/19/16")

arrow_df <- data.frame(x = as.Date("2015-05-19"),
                       y = 60,
                       xend = as.Date("2015-06-01"),
                       yend = 65)

ggplot(time_df, aes(x = date, y = num_tweets)) +
  geom_line(col = "gray") +
  theme_bw() +
  geom_label(
    data = data.frame(x = c(as.Date("2015-05-19"), as.Date("2017-4-15"), as.Date("2018-01-15")),
                      y = c(120, 105, 90),
                      label = c("Refugio oil spill", "Thomas fire starts", "Debris flow")),
    aes(x = x, y = y, label = label), 
    hjust = 0, 
    lineheight = .8, 
    size = 3,
    inherit.aes = FALSE, 
    label.size = 0
  ) +
  geom_curve(
    data = data.frame(x = c(as.Date("2015-05-19"), as.Date("2017-12-04"), as.Date("2018-01-08")),
                      y = c(120, 100, 88), 
                      xend = c(as.Date("2015-06-01"), as.Date("2017-12-04"), as.Date("2018-01-08")),
                      yend = c(65, 40, 50)),
    mapping = aes(x = x, y = y, xend = xend, yend = yend),
    colour = "black",
    size = 0.5,
    curvature = 0.05,
    arrow = arrow(length = unit(0.01, "npc"), type = "closed"),
    inherit.aes = FALSE) +
  labs(x = "",
       y = "Number of geo-tagged tweets")


```

The big decrease in number of tweets ends right at October 31, 2016. I'm still not 100% sure what is happening but this seems to hold across twitter. From the [Twitter API page](https://developer.twitter.com/en/docs/ads/general/overview/versions), Version 0.0 was deprecated on that date

# Nature based approach

## Applying dictionary

The dictionary is "nature-based" and is al ist of words I put together. I had a hard time finding an ontology or lexicon that would fit this project. These are definitely skewed more towards nature and recreation rather than words like "home" or "connection".

```{r}
dictionary <- read_csv("data/dictionary.csv")

dictionary$word
```

I looked for any of these within the geo-tagged tweets to identify "nature-based" or not. 

```{r, echo = F}
nature_df <- read_csv("data/tweets_nature_categorized.csv")%>%
  separate(created_at, into = c("Day", "Year"), sep = 26) %>%
  mutate(Year = as.numeric(Year)) %>%
  separate(Day, into = c("Day", "Date"), sep = 4) %>%
  separate(Date, into = c("Date", "Time"), sep = 7) %>%
  separate(Time, into = c("Time", "Extra"), sep = 9) %>%
  dplyr::select(-Extra, -tweet_id, -language, -geo_type, -id, -location, -user_id, -Day) %>%
  separate(Date, into = c("Month", "Day"), sep = " ") %>%
  mutate(Day = as.numeric(Day)) %>%
  mutate(month_num = match(Month,month.abb)) %>%
  mutate(date = as.Date(paste0(month_num, "/", Day, "/",Year),tryFormats = "%m/%d/%Y"))
```

Using this dictionary, there are `r nrow(filter(nature_df, nature_word == 1))` nature-based tweets (`r round(nrow(filter(nature_df, nature_word == 1))/nrow(nature_df), 2)*100`%)

Here are some examples of tweets, the column `nature_word` identifies if it is nature based (1) or not (0).

```{r}
#selecting just a few columns
ndf <- nature_df %>%
  select(date, full_text, user_type, nature_word)

kable(sample_n(ndf, 40)) %>%
  kable_styling(bootstrap_options = c("striped", "condensed"), font_size = 10, fixed_thead = T)
```


```{r, echo = F}
#santa barbara
sb.map <- get_map("santa barbara, california", zoom = 13, maptype = "toner-lite") 

ggmap(sb.map,  legend="none") +
  coord_equal() +
    labs(x = NULL, y = NULL) +
    theme(axis.text = element_blank()) +
    geom_hex(data = nature_df %>% filter(nature_word == 1), aes(x=lon, y=lat, fill = cut(..count.., c(0, 10, 50, 100,
                                    500, 1000, Inf))), bins=100) +
       scale_fill_viridis(discrete = TRUE,
        labels = c("<10 ", "10-49 ", "50-99 ",
                   "100-499 ", "500-999 ", "1000+")
    ) +
  labs(fill = "# Tweets",
       title = "Santa Barbara Nature based tweets")
```



```{r, echo = F}
#goleta
gol.map <- get_map("goleta, california", zoom = 12, maptype = "toner-lite") 

ggmap(gol.map,  legend="none") +
  coord_equal() +
    labs(x = NULL, y = NULL) +
    theme(axis.text = element_blank()) +
    geom_hex(data = nature_df %>% filter(nature_word == 1), aes(x=lon, y=lat, fill = cut(..count.., c(0, 10, 50, 100, 200,
                                    300, Inf))), bins=100) +
       scale_fill_viridis(discrete = TRUE,
        labels = c("<10 ", "10-49 ", "50-99 ",
                   "100-199 ", "200-299 ", "300+ ")
    ) +
  labs(fill = "# Tweets",
       title = "Goleta Nature based tweets") 
```



```{r, eval = F, echo = F}
#map
map <- leaflet() %>%
  # Base groups
  addProviderTiles(providers$CartoDB.Positron) %>%
  # Overlay groups
  addCircleMarkers(data = nature_df %>% filter(nature_word == 0), lng = ~lon, lat = ~lat, popup = ~full_text,
                   radius = 3, stroke = FALSE,
                   color = "grey", fillOpacity = 0.8, group = "Other") %>%
    addCircleMarkers(data = nature_df %>% filter(nature_word == 1), lng = ~lon, lat = ~lat, popup = ~full_text,
                   radius = 3, stroke = FALSE,
                   color = "darkgreen", fillOpacity = 0.5, group = "Nature") %>%
  # Layers control
  addLayersControl(
    overlayGroups = c("Nature", "Other"),
    options = layersControlOptions(collapsed = FALSE)
  ) 

map
```

Where are locals tweeting naturebased tweets from? And where are tourists tweeting naturebased tweets from?

```{r, echo = F}
#santa barbara
sb.map <- get_map("santa barbara, california", zoom = 14, maptype = "toner-lite") 

ggmap(sb.map,  legend="none") +
  coord_equal() +
    labs(x = NULL, y = NULL) +
    theme(axis.text = element_blank()) +
    geom_hex(data = nature_df %>% filter(nature_word == 1), 
             aes(x=lon, y=lat, fill = cut(..count.., c(0, 10, 50, 100, 500, 1000, Inf))), bins=100) +
  scale_fill_viridis(discrete = TRUE,
        labels = c("<10 ", "10-49 ", "50-99 ",
                   "100-499 ", "500-999 ", "1000+")
    ) +
  facet_wrap(~user_type) +
  theme(legend.position = "bottom") +
  labs(fill = "# Tweets",
       title = "Santa Barbara Nature-based tweets")

```

```{r, echo = F}
gol.map <- get_map("goleta, california", zoom = 13, maptype = "toner-lite") 

ggmap(gol.map,  legend="none") +
  coord_equal() +
    labs(x = NULL, y = NULL) +
    theme(axis.text = element_blank()) +
    geom_hex(data = nature_df %>% filter(nature_word == 1), 
             aes(x=lon, y=lat, fill = cut(..count.., c(0, 5, 10, 50, 100, Inf))), bins=100) +
  scale_fill_viridis(discrete = TRUE,
        labels = c("<5 ", "5-9 ", "10-49 ",
                   "50-99 ", "100+")
    ) +
  facet_wrap(~user_type) +
  theme(legend.position = "bottom") +
  labs(fill = "# Tweets",
       title = "Goleta Nature-based tweets")

```

```{r, echo = F, eval = F}

nature_time_df <- nature_df %>%
  mutate(type = ifelse(nature_word == 1, "Nature-based", "Other")) %>%
  group_by(date, type) %>%
  summarize(num_tweets = n())

ggplot(nature_time_df, aes(x = date, y = num_tweets, color = type)) +
  geom_line() +
  theme_bw() +
  #facet_wrap(~type, scales = "free_y") +
  geom_label(
    data = data.frame(x = c(as.Date("2015-05-19"), as.Date("2017-4-15"), as.Date("2018-01-15")),
                      y = c(120, 105, 90),
                      label = c("Refugio oil spill", "Thomas fire starts", "Debris flow")),
    aes(x = x, y = y, label = label), 
    hjust = 0, 
    lineheight = .8, 
    size = 3,
    inherit.aes = FALSE, 
    label.size = 0
  ) +
  geom_curve(
    data = data.frame(x = c(as.Date("2015-05-19"), as.Date("2017-12-04"), as.Date("2018-01-08")),
                      y = c(120, 100, 88), 
                      xend = c(as.Date("2015-06-01"), as.Date("2017-12-04"), as.Date("2018-01-08")),
                      yend = c(65, 40, 50)),
    mapping = aes(x = x, y = y, xend = xend, yend = yend),
    colour = "black",
    size = 0.5,
    curvature = 0.05,
    arrow = arrow(length = unit(0.01, "npc"), type = "closed"),
    inherit.aes = FALSE) +
  labs(x = "",
       y = "Number of geo-tagged tweets")

#plotly::ggplotly()
```


# What are the places people are tweeting from?

Using the California Protected Areas database we can see how often a geo-tagged tweet from a designated area is nature-based or not.

```{r, echo = F}
nature_df_sf <- nature_df %>%
    mutate(coords = gsub("\\)|c\\(", "", geo_coordinates)) %>%
    separate(coords, c("lat", "lon"), sep = ", ") %>%
    mutate_at(c("lon", "lat"), as.numeric) %>% 
    st_as_sf(coords = c("lon", "lat")) %>%
    st_set_crs("+init=epsg:4326") %>%
  mutate(tweet_type = ifelse(nature_word == 1, "nature tweet", "non-nature tweet"),
         nature_user = case_when(
            user_type == "local" & nature_word == 0 ~ "local, non nature tweet",
            user_type == "tourist" & nature_word == 0 ~ "tourist, non nature tweet",
            user_type == "tourist" & nature_word == 1 ~ "tourist, nature tweet",
            user_type == "local" & nature_word == 1 ~ "local, nature tweet"
        ))
```

```{r, echo = F}
cpad <- read_sf("data/CPAD_2019a/CPAD_2019a_Holdings.shp") %>%
  filter(COUNTY == "Santa Barbara") %>%
  st_transform("+init=epsg:4326") %>%
  st_crop(xmin = -119.5, xmax = -120.5, ymin = 33.88, ymax = 34.6)

#mapview(cpad)
```


```{r, echo = F}
non_nature_tweets <- nature_df_sf %>% 
  filter(nature_word == 0)

cpad_all_count <- cpad %>%
  mutate(nature_count = lengths(st_intersects(cpad, nature_df_sf)),
         non_nature_count = lengths(st_intersects(cpad, non_nature_tweets))) %>%
  rowwise() %>%
  mutate(
         ratio = nature_count/non_nature_count,
         prop  = nature_count/sum(c(nature_count, non_nature_count))) %>%
  filter(!is.na(ratio)) %>%
  mutate(ratio = ifelse(is.infinite(ratio), nature_count, ratio)) %>% 
  st_set_geometry("geometry")
```

Map of protected areas and their proportion and ratio of naturebased tweets to non-nature based tweets. You can select layers to turn on and off on the left hand side.

```{r, echo = F}
site_locations <- 
  mapview(cpad_all_count, zcol = "prop") +
  mapview(cpad_all_count, zcol = "ratio") 

site_locations
```

Do locals engage more than tourists in protected areas? Proportion and ratio of tweets by locals compared to tourists.

```{r, echo = F}
tourist_pa <- nature_df_sf %>%
  filter(nature_user == "tourist, nature tweet")

local_pa <- nature_df_sf %>%
  filter(nature_user == "local, nature tweet")


cpad_usertype_count <- cpad %>%
  mutate(tourist_count = lengths(st_intersects(cpad, tourist_pa)),
         local_count = lengths(st_intersects(cpad, local_pa))) %>%
  rowwise() %>%
  mutate(
         ratio = local_count/tourist_count,
         prop  = local_count/sum(c(local_count, tourist_count))) %>%
  filter(!is.na(ratio)) %>%
  mutate(ratio = ifelse(is.infinite(ratio), local_count, ratio)) %>% 
  st_set_geometry("geometry")

site_locations <- 
  mapview(cpad_usertype_count, zcol = "prop") +
  mapview(cpad_usertype_count, zcol = "ratio") 

site_locations
```


```{r,eval = F, echo = F}
nature_sp <-  read_csv("data/tweets_nature_categorized.csv") %>% 
    st_as_sf(coords = c("lon", "lat")) %>%
    st_set_crs("+init=epsg:4326") %>%
  as("Spatial")
```

```{r, eval = F, echo = F}
r <- raster(xmn=-120.5, ymn=33.88, xmx=-119.5, ymx=34.6, res=0.005)

x <- rasterize(nature_sp, r, field = "id", fun='count')
```



```{r, eval = F, echo = F}
leaflet() %>% addProviderTiles(providers$CartoDB.Positron) %>%
  addRasterImage(x, opacity = 0.7) %>% 
  fitBounds(-119.8,34.3,-119.6,34.6) %>%
  setMaxBounds(-120, 33.88, -119.5, 34.6)
```


```{r, eval = F, echo = F}
#take the log
logx <- log(x)

leaflet() %>% addProviderTiles(providers$CartoDB.Positron) %>%
  addRasterImage(logx, opacity = 0.7) %>% 
  fitBounds(-119.8,34.3,-119.6,34.6) %>%
  setMaxBounds(-120, 33.88, -119.5, 34.6)
```


Next steps

- sentiment analysis
- only look at tweets with photos? could do some sort of machine learning process to identify whats in the photos
- how do ratios of nature/non-nature in protected areas change over time?
- do locals engage more with protected areas than tourists?
